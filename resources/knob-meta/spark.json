[
  {
    "id": "k1",
    "name": "spark.executor.memory",
    "type": "INTEGER",
    "unit": "g",
    "min": 2,
    "max": 16,
    "scale": "linear",
    "factor": 2,
    "base": null,
    "enum": null,
    "bools": null,
    "default": "16g",
    "desc": "set among 8G-64G. Default: 16g"
  },
  {
    "id": "k2",
    "name": "spark.executor.cores",
    "type": "INTEGER",
    "unit": null,
    "min": 2,
    "max": 5,
    "scale": "linear",
    "factor": 1,
    "base": null,
    "enum": null,
    "bools": null,
    "default": "5",
    "desc": "set among 2-5. Default: 5 as recommended by the best practice"
  },
  {
    "id": "k3",
    "name": "spark.executor.instances",
    "type": "INTEGER",
    "unit": null,
    "min": 4,
    "max": 10,
    "scale": "linear",
    "factor": 1,
    "base": null,
    "enum": null,
    "bools": null,
    "default": "4",
    "desc": "set among 4-10, provide 8-50 cores in total. Default: 4"
  },
  {
    "id": "k4",
    "name": "spark.default.parallelism",
    "type": "INTEGER",
    "unit": null,
    "min": 1,
    "max": 3,
    "scale": "linear",
    "factor": 1,
    "base": null,
    "enum": null,
    "bools": null,
    "default": "40",
    "desc": "spark.default.parallelism = k2 * k3 * k4. Default: k4 = 2, parallel = 5 * 4 * 2 = 40"
  },
  {
    "id": "k5",
    "name": "spark.reducer.maxSizeInFlight",
    "type": "INTEGER",
    "unit": "m",
    "min": 0,
    "max": 5,
    "scale": "log",
    "factor": 12,
    "base": 2,
    "enum": null,
    "bools": null,
    "default": "48m",
    "desc": "factor * (base ^ k5), set among 12M-384M. Default: 48M when k5 = 2"
  },
  {
    "id": "k6",
    "name": "spark.shuffle.sort.bypassMergeThreshold",
    "type": "BOOL",
    "unit": null,
    "min": null,
    "max": null,
    "scale": null,
    "factor": null,
    "base": null,
    "enum": null,
    "bools": [false, true],
    "default": "200",
    "desc": "set spark.shuffle.sort.bypassMergeThreshold < (k2 * k3 * k4) when True, > (k2 * k3 * k4) when False"
  },
  {
    "id": "k7",
    "name": "spark.shuffle.compress",
    "type": "BOOL",
    "unit": null,
    "min": null,
    "max": null,
    "scale": null,
    "factor": null,
    "base": null,
    "enum": null,
    "bools": [false, true],
    "default": "true",
    "desc": "F/T, default: true"
  },
  {
    "id": "k8",
    "name": "spark.memory.fraction",
    "type": "INTEGER",
    "unit": null,
    "min": 50,
    "max": 75,
    "scale": "linear",
    "factor": 0.01,
    "base": null,
    "enum": null,
    "bools": null,
    "default": "0.6",
     "desc": "set among 0.50-0.75, default 0.6, precision: 2"
  },
  {
    "id": "s1",
    "name": "spark.sql.inMemoryColumnarStorage.batchSize",
    "type": "INTEGER",
    "unit": null,
    "min": 0,
    "max": 4,
    "scale": "log",
    "factor": 2500,
    "base": 2,
    "enum": null,
    "bools": null,
    "default": "10000",
    "desc": "set among 2500-40000, default: 10000"
  },
  {
    "id": "s2",
    "name": "spark.sql.files.maxPartitionBytes",
    "type": "INTEGER",
    "unit": "MB",
    "min": 0,
    "max": 4,
    "scale": "log",
    "factor": 32,
    "base": 2,
    "enum": null,
    "bools": null,
    "default": "128MB",
    "desc": "set among 32MB-512MB, default: 128MB"
  },
  {
    "id": "s3",
    "name": "spark.sql.autoBroadcastJoinThreshold",
    "type": "INTEGER",
    "unit": "MB",
    "min": 0,
    "max": 6,
    "scale": "log",
    "factor": 5,
    "base": 2,
    "enum": null,
    "bools": null,
    "default": "10MB",
    "desc": "set among 5MB-320MB, default 10MB"
  },
  {
    "id": "s4",
    "name": "spark.sql.shuffle.partitions",
    "type": "BOOL",
    "unit": null,
    "min": null,
    "max": null,
    "scale": null,
    "factor": null,
    "base": null,
    "enum": null,
    "bools": [false, true],
    "default": "200",
    "desc": "set spark.sql.shuffle.partitions = spark.default.parallelism when true, 2001 when False. Note that the largest parallelism in our experiment is < 2000 when sql.shuffle.partitions, the system uses a highly compression method during shuffling"
  }
]