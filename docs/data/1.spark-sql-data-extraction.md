# Data Extraction in Spark


## Pure SQL

Target dataset: [TPCH](../../resources/dataset/tpch_100_query_traces) and [TPCDS](../../resources/dataset/tpcds_100_query_traces).

1. get operator features via `d2v`
```bash
export PYTHONPATH="$PWD"
python examples/data/spark/1.operator_encoding.py -b TPCH --scale-factor 100 \
--src-path-header resources/dataset/tpch_100_query_traces --cache-header examples/data/spark/cache \
--workers 24 --debug 0 --mode d2v --frac-per-struct 0.02 --tuning 1 --vec-size 200 --epochs 10000 --alpha 0.05
```

2. get query-level tabular features
```bash
export PYTHONPATH="$PWD"
python examples/data/spark/2.sql_struct_extraction.py -b TPCH --scale-factor 100 \
--src-path-header resources/dataset/tpch_100_query_traces --cache-header examples/data/spark/cache
```