Here we show the detailed steps for collecting Spark-TPCxBB over Ercilla:

Step1. Setup the benchmark over a Spark cluster (Ercilla)

```bash
git clone git@github.com:Angryrou/Big-Data-Benchmark-for-Big-Bench.git -b hex
cd Big-Data-Benchmark-for-Big-Bench

export BIG_BENCH_HOME=~/chenghao/Big-Data-Benchmark-for-Big-Bench
export PATH=${BIG_BENCH_HOME}/bin/:${PATH}

export sf=100
export BIG_BENCH_DEFAULT_DATABASE="bigbench_sf_$sf"

export SPARK_PARAMS="\
--master yarn \
--deploy-mode client \
--name populate_metastore_${sf} \
--driver-cores 5 \
--driver-memory 30g \
--executor-cores 5 \
--executor-memory 30g \
--num-executors 20 \
--conf spark.default.parallelism=100"

./bin/bigBench runBenchmark -m 20 -f $sf -s 2 -i DATA_GENERATION,LOAD_TEST
```

Step2. analyze tables and columns in the benchmark.
```bash
# enter spark-shell
spath=/opt/hex_users/$USER/chenghao/spark-sql-perf
jpath=/opt/hex_users/$USER/spark-3.2.1-hadoop3.3.0/jdk1.8
lpath=/opt/hex_users/$USER/chenghao/spark-sql-perf/src/main/resources/log4j.properties
sparkpath=/opt/hex_users/$USER/spark
respath=/opt/hex_users/$USER/chenghao/spark-sql-perf/src/main/resources/tpcxbb/res

~/spark/bin/spark-shell \
--master yarn \
--deploy-mode client \
--conf spark.executorEnv.JAVA_HOME=${jpath} \
--conf spark.yarn.appMasterEnv.JAVA_HOME=${jpath} \
--conf spark.executor.memory=16g \
--conf spark.executor.cores=5 \
--conf spark.executor.instances=4 \
--conf spark.default.parallelism=40 \
--conf spark.reducer.maxSizeInFlight=48m \
--conf spark.shuffle.sort.bypassMergeThreshold=200 \
--conf spark.shuffle.compress=true \
--conf spark.memory.fraction=0.6 \
--conf spark.sql.inMemoryColumnarStorage.batchSize=10000 \
--conf spark.sql.files.maxPartitionBytes=128MB \
--conf spark.sql.autoBroadcastJoinThreshold=10MB \
--conf spark.sql.shuffle.partitions=200 \
--conf spark.yarn.am.cores=5 \
--conf spark.yarn.am.memory=16g \
--conf spark.sql.adaptive.enabled=false \
--conf spark.sql.parquet.compression.codec=snappy \
--conf spark.sql.broadcastTimeout=10000 \
--conf spark.rpc.askTimeout=12000 \
--conf spark.shuffle.io.retryWait=60 \
--conf spark.sql.statistics.histogram.enabled=true \
--conf spark.serializer=org.apache.spark.serializer.KryoSerializer \
--conf spark.kryoserializer.buffer.max=512m \
--files=${respath}/*.py,${respath}/log4j.properties \
--driver-java-options "-Dlog4j.configuration=file:$lpath" \
--conf "spark.driver.extraJavaOptions=-Xms20g" \
--conf "spark.executor.extraJavaOptions=-Dlog4j.configuration=file:log4j.properties" \
--jars ${respath}/bigbenchqueriesmr.jar,${respath}/opennlp-tools-1.6.0.jar,${sparkpath}/examples/jars/scopt_2.12-3.7.1.jar,$spath/target/scala-2.12/spark-sql-perf_2.12-0.5.1-SNAPSHOT.jar
```

```scala
// in the spark-shell

sql("use bigbench_sf_100").show()

val tbl_df = sql("show tables")
val tbl_names = tbl_df.select("tableName").collect().map(_.getString(0))

for (name <- tbl_names) {
    println(s"Analyzing table $name.")
    sql(s"ANALYZE TABLE $name COMPUTE STATISTICS")
    sql(s"ANALYZE TABLE $name COMPUTE STATISTICS FOR ALL COLUMNS")
}
```

Step3. Example of running TPCxBB
```bash
   export PYTHONPATH="$PWD"
   # run 1-1.sql in the default configuration
   python examples/trace/spark/3.run_one_tpcxbb.py

   # run 30 template queries in the isolated env
   python examples/trace/spark/4.run_all_single_query_env.py -b TPCxBB -q resources/tpcxbb-kit/spark-sqls --num-templates 30 --worker $USER
   
   # running 30 template queries in the multi-query env
   # (1) configuration generation
   python examples/trace/spark/5.generate_scripts_for_lhs_tpcxbb.py -b TPCxBB --num-processes 30 --num-templates 30
   # (2) running for debug 
   python examples/trace/spark/6.run_all_pressure_test_tpcxbb.py -b TPCxBB --id-template-end 1 --debug 1 --worker debug
   # (3) running for collection 
   python examples/trace/spark/6.run_all_pressure_test_tpcxbb.py \
   -b TPCxBB \
   --id-template-start 0 \
   --id-template-end 1428 \
   --debug 0 \
   --num-processes 22 \
   --worker hex2
   
   python examples/trace/spark/6.run_all_pressure_test_tpcxbb.py \
   -b TPCxBB \
   --id-template-start 1428 \
   --id-template-end  2856 \
   --debug 0 \
   --num-processes 22 \
   --worker hex3
```

