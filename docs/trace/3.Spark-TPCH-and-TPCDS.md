Here we show the detailed steps for collecting Spark-TPCH over Ercilla

1. Setup the benchmark over a Spark cluster:

```bash
git clone https://github.com/Angryrou/spark-sql-perf.git
cd spark-sql-perf
bin/run --help # testing env
sbt +package

# an example of running in our Ercilla Spark cluster, look into `my_set_benchmark.sh` for more details
bm=TPCH # TPCDS
sf=100
bash ~/chenghao/spark-sql-perf/src/main/scripts/benchmark_sf_testing/my_set_benchmark.sh $bm $sf
```

2. Prepare the codebase for query generation (clone, compile and validate).

```bash
# add tpch-kit under `resources`
OS=MACOS # or LINUX, for both Spark and Postgres
bash examples/trace/1.setup_tpch.sh MACOS

# add tpcds-kit under `resources`
# todo
```

3. Generate SparkSQLs. 

```bash
# bash examples/trace/spark/1.query_generation_tpch.sh <tpch-kit path> <query-out path> <#queries per template> <SF-100 by default>
# local:
bash examples/trace/spark/1.query_generation_tpch.sh $PWD/resources/tpch-kit $PWD/resources/tpch-kit/spark-sqls 3
# TPCH:
bash examples/trace/spark/1.query_generation_tpch.sh $PWD/resources/tpch-kit $PWD/resources/tpch-kit/spark-sqls 4545
# TPCDS:
# todo
```

4. Generate configurations via LHS and BO. Check the example below

```bash
export PYTHONPATH="$PWD"
python examples/trace/spark/2.knob_sampling.py
```

5. (optional) Explore the property of trace collection over TPCH
   - an example of running single query in our Ercilla Spark cluster.
    ```bash
    export PYTHONPATH="$PWD"
    python examples/trace/spark/3.run_one.py
    ```
   - an example in the single-query environment
   ```bash
   export PYTHONPATH="$PWD"
   python examples/trace/spark/4.run_all_single_query_env.py
   ```
   - an example in the multi-query environment
   ```bash
   export PYTHONPATH="$PWD"
   python examples/trace/spark/5.generate_scripts_for_lhs.py --num-processes 30
   # pressure test
   python examples/trace/spark/6.run_all_pressure_test.py --num-processes 22 --num-queries-per-template-to-run 3637 
   ```

6. TPCH collection 

```bash
export PYTHONPATH="$PWD"
# generate configurations via LHS
python examples/trace/spark/5.generate_scripts_for_lhs.py -b TPCH -q resources/tpch-kit/spark-sqls --num-processes 30 --num-templates 22 --num-queries-per-template 3637
# run LHS configurations 
python examples/trace/spark/6.run_all_pressure_test.py -b TPCH --num-processes 22 --num-templates 22 --num-queries-per-template-to-run 3637 
```
